<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Soumya Rani</title>
  
  <meta name="author" content="Soumya Rani Samineni">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Soumya Rani Samineni</name>
              </p>
              <p>I am an AI Engineer at a startup company AI Labs based out of Hyderabad where I work on Artificial Intelligence and Machine Learning.
              </p>
              <p>
                At AI Labs, I've worked on Object Detection Models and Reinforcement Learning for Robotics Control. I did my Masters in <a href="https://www.csa.iisc.ac.in/"> Computer Science and Automation, IISc Bangalore </a>, where I was advised by Prof <a href="https://shishirny.github.io/"> Shishir Kolathaya</a> and Prof <a href="https://www.csa.iisc.ac.in/~shalabh/">Shalabh Bhatnagar</a>.
                <br> 
                <br> My Masters thesis titled Policy search using Dynamic Mirror Descent for offpolicy RL has received funding from <a href="https://cps.iisc.ac.in/"> Robert Bosch Center for Cyber Physical Systems (RBCCPS) </a>. Also, I was part of both <a href="https://www.csa.iisc.ac.in/~shalabh/"> </a>Stochastic Systems Lab and <a href="http://stochlab.github.io/"> Stochastic Robotics Lab</a> at IISc. 
                <br> Before joining IISC, I have worked as an Assitant Executive Engineer(Civil) for Government of Telangana. I did my bachelors in Civil Engineering from <a href="https://nitw.ac.in/"> National Institute of Technology Warangal</a>.
                <!---I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.--->
              </p>
              <p style="text-align:center">
                <a href="mailto:saminenisoumyarani@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Soumya-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/Soumya-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/soumya_samineni">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/soumyarani">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/soumya_passport.jpg"><img style="width:50%;max-width:100%" alt="profile photo" src="images/soumya_passport.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in reinforcement learning, machine learning, stochastic approximation, optimization, and deep learning. Much of my research is about novel RL algorithms that are optimal and sample efficient. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mipnerf_ipe_yellow.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=Re6QSi8hXQ">
                <papertitle>Dynamic Mirror Descent based Model Predictive Control for Accelerating Robot Learning </papertitle>
              </a>
              <br>
              <a href="https://utkarshmishra04.github.io/">Utkarsh Mishra*</a>,
              <strong>Soumya R Samineni*</strong>,
              <a href= "https://www.csa.iisc.ac.in/~shalabh/">Shalabh Bhatnagar </a>, <a href="https://shishirny.github.io/"> Shishir Kolathaya </a> 
              <br> (*equal contribution) <br>
							<em>NIPS Deep RL Workshop</em>, 2021 &nbsp <font color="red"><strong>(Poster)</strong></font> <br>
							<em>NIPS Offline RL Workshop</em>, 2021 &nbsp <font color="red"><strong>(Poster)</strong></font><br>
              <em>ICRA</em>, 2021 &nbsp <font color="green">(Under Review)</font><br>
              <br>
              <a href="">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=Bj9dN1KNPAs">video</a>
							/
              <a href="https://github.com/soumyarani/mopac">code</a>
              <p></p>
              <p>Dynamic Mirror Descent is applied for an H step lookahead policy optimisation to augment the dataset for training an offpolicy RL, improving significantly the sample efficincy of SAC. Further the proposed framework, DeMoRL generalises existing Mb Mf Approaches.</p>
            </td>
          </tr> 
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
